{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹å·¥ä½œè·¯å¾„: /workspace\n",
      "æ–°å·¥ä½œè·¯å¾„: /workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"åŸå§‹å·¥ä½œè·¯å¾„:\", os.getcwd())\n",
    "os.chdir(\"/workspace/\")\n",
    "print(\"æ–°å·¥ä½œè·¯å¾„:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://mirrors.cloud.tencent.com/ubuntu focal InRelease [265 kB]\n",
      "Hit:2 http://mirrors.cloud.tencent.com/ubuntu focal-security InRelease         \n",
      "Hit:3 http://mirrors.cloud.tencent.com/ubuntu focal-updates InRelease          \n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Fetched 265 kB in 1s (463 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Calculating upgrade... Done\n",
      "The following packages have been kept back:\n",
      "  libcudnn9-cuda-12 libcudnn9-dev-cuda-12 libnccl-dev libnccl2\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "cmake is already the newest version (3.16.3-1ubuntu1.20.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libcurl4-gnutls-dev is already the newest version (7.68.0-1ubuntu2.25).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get -y update\n",
    "!apt-get -y upgrade\n",
    "!apt-get install -y cmake\n",
    "!apt-get install -y libcurl4-gnutls-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: pip in /root/miniforge3/lib/python3.11/site-packages (25.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: ipywidgets in /root/miniforge3/lib/python3.11/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /root/miniforge3/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /root/miniforge3/lib/python3.11/site-packages (from ipywidgets) (9.1.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /root/miniforge3/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /root/miniforge3/lib/python3.11/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /root/miniforge3/lib/python3.11/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /root/miniforge3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in /root/miniforge3/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /root/miniforge3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/miniforge3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /root/miniforge3/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /root/miniforge3/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /root/miniforge3/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.11.3: Fast Qwen2 patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    Tesla V100-SXM2-32GB. Num GPUs = 1. Max memory: 31.739 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e9da6eba80410c828aa7b3a0f68afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ç”¨ Unsloth åº“çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œä»¥4ä½é‡åŒ–+æ¢¯åº¦æ£€æŸ¥ç‚¹çš„æ–¹å¼ï¼Œä½æ˜¾å­˜åŠ è½½é«˜æ€§èƒ½çš„ Qwen2.5-14B æŒ‡ä»¤å¾®è°ƒæ¨¡å‹\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# è°ƒç”¨Unslothå°è£…çš„from_pretrainedæ–¹æ³•ï¼ŒåŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œé…å¥—åˆ†è¯å™¨\n",
    "# è¿”å›å€¼ï¼šmodelä¸ºé‡åŒ–åçš„Qwen2.5-14Bæ¨¡å‹å®ä¾‹ï¼Œtokenizerä¸ºæ¨¡å‹é…å¥—çš„åˆ†è¯å™¨å®ä¾‹\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # æŒ‡å®šåŠ è½½çš„æ¨¡å‹åç§°/è·¯å¾„ï¼šUnslothä¼˜åŒ–çš„Qwen2.5-14BæŒ‡ä»¤å¾®è°ƒç‰ˆï¼ˆbnb-4bitè¡¨ç¤º4ä½é‡åŒ–ç‰ˆæœ¬ï¼‰\n",
    "    # è¯¥æ¨¡å‹ä¸“ä¸ºå¯¹è¯/æŒ‡ä»¤æ‰§è¡Œåœºæ™¯è®¾è®¡ï¼Œå¼€ç®±å³ç”¨4ä½é‡åŒ–ï¼Œé™ä½æ˜¾å­˜é—¨æ§›\n",
    "    model_name = \"unsloth/Qwen2.5-14B-Instruct-bnb-4bit\",\n",
    "    # å¯ç”¨4ä½é‡åŒ–åŠ è½½æ¨¡å‹ï¼ˆåŸºäºbitsandbyteså®ç°ï¼‰ï¼Œæ˜¾å­˜å ç”¨æ¯”FP16é™ä½75%ï¼ˆ14Bæ¨¡å‹ä»…éœ€8-10GBæ˜¾å­˜ï¼‰\n",
    "    load_in_4bit = True,\n",
    "    # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰ï¼šåå‘ä¼ æ’­æ—¶ä¸ä¿å­˜æ‰€æœ‰ä¸­é—´æ¿€æ´»å€¼ï¼Œä»¥è®¡ç®—æ¢æ˜¾å­˜\n",
    "    # è¿›ä¸€æ­¥é™ä½è®­ç»ƒ/æ¨ç†æ—¶çš„æ˜¾å­˜æ¶ˆè€—ï¼Œå¯¹14Bçº§å¤§æ¨¡å‹è‡³å…³é‡è¦\n",
    "    use_gradient_checkpointing = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.11.3 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# ä¸ºå·²åŠ è½½çš„é‡åŒ–æ¨¡å‹é…ç½®LoRAï¼ˆä½ç§©é€‚é…ï¼‰å¾®è°ƒç­–ç•¥ï¼Œè¿”å›é€‚é…åçš„æ¨¡å‹å®ä¾‹\n",
    "# FastLanguageModel.get_peft_modelæ˜¯Unslothå°è£…çš„PEFTä¼˜åŒ–æ–¹æ³•ï¼Œä¸“ä¸ºå¤§æ¨¡å‹ä½æ˜¾å­˜å¾®è°ƒè®¾è®¡\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "   model,  # ä¼ å…¥ä¹‹å‰åŠ è½½çš„Qwen2.5-14Bé‡åŒ–æ¨¡å‹å®ä¾‹\n",
    "   r = 16,  # LoRAä½ç§©çŸ©é˜µçš„ç§©ï¼ˆæ ¸å¿ƒè¶…å‚æ•°ï¼‰ï¼Œæ§åˆ¶ä½ç§©çŸ©é˜µçš„ç»´åº¦ï¼›rè¶Šå¤§å¯æ‹Ÿåˆçš„ä¿¡æ¯è¶Šå¤šï¼Œä½†æ˜¾å­˜å ç”¨ç•¥å¢\n",
    "            # 16æ˜¯Qwen2.5-14Bçš„æ¨èå€¼ï¼Œå¹³è¡¡æ•ˆæœä¸æ˜¾å­˜\n",
    "   # æŒ‡å®šå¯¹æ¨¡å‹å“ªäº›æ¨¡å—æ³¨å…¥LoRAå‚æ•°ï¼ˆQwen2.5åŸºäºTransformeræ¶æ„ï¼Œæ ¸å¿ƒæ³¨æ„åŠ›/å‰é¦ˆå±‚ï¼‰\n",
    "   # q/k/v/o_projï¼šæ³¨æ„åŠ›å±‚çš„æŸ¥è¯¢/é”®/å€¼/è¾“å‡ºæŠ•å½±å±‚ï¼›gate/up/down_projï¼šå‰é¦ˆç½‘ç»œçš„æ ¸å¿ƒå±‚\n",
    "   # ä»…å¯¹è¿™äº›æ ¸å¿ƒå±‚å¾®è°ƒï¼Œæ—¢ä¿è¯æ•ˆæœåˆå‡å°‘å‚æ•°é‡\n",
    "   target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "   lora_alpha = 16,  # LoRAçš„ç¼©æ”¾ç³»æ•°ï¼Œä¸ré…åˆä½¿ç”¨ï¼ˆå»ºè®®å’Œrå–å€¼ç›¸åŒï¼‰ï¼Œç”¨äºå¹³è¡¡LoRAå‚æ•°çš„æ›´æ–°å¹…åº¦\n",
    "   lora_dropout = 0,  # LoRAå±‚çš„Dropoutæ¦‚ç‡ï¼Œ0è¡¨ç¤ºä¸ä½¿ç”¨Dropoutï¼ˆå°æ•°æ®é›†/æŒ‡ä»¤å¾®è°ƒåœºæ™¯æ¨è0ï¼Œé¿å…è¿‡æ‹Ÿåˆï¼‰\n",
    "   bias = \"none\",     # æ˜¯å¦è®­ç»ƒæ¨¡å‹çš„åç½®å‚æ•°ï¼š\"none\"è¡¨ç¤ºä¸è®­ç»ƒä»»ä½•åç½®ï¼Œè¿›ä¸€æ­¥å‡å°‘è®­ç»ƒå‚æ•°é‡ï¼ˆä¸»æµé€‰æ‹©ï¼‰\n",
    "   # å¯ç”¨Unslothå®šåˆ¶çš„æ¢¯åº¦æ£€æŸ¥ç‚¹ä¼˜åŒ–ï¼ˆ\"unsloth\"æ¨¡å¼ï¼‰ï¼Œç›¸æ¯”åŸç”ŸPyTorchç‰ˆæœ¬æ˜¾å­˜å ç”¨å†é™20%-30%\n",
    "   # åŸç†ï¼šæ›´ç²¾ç»†åœ°æ§åˆ¶æ¿€æ´»å€¼çš„ä¿å­˜/é‡è®¡ç®—ï¼Œé€‚é…LoRAå¾®è°ƒçš„æ˜¾å­˜ç‰¹æ€§\n",
    "   use_gradient_checkpointing = \"unsloth\", \n",
    "   random_state = 3407,  # éšæœºç§å­ï¼Œå›ºå®šç§å­ä¿è¯å®éªŒå¯å¤ç°ï¼ˆ3407æ˜¯LLMå¾®è°ƒçš„ç»å…¸é»˜è®¤å€¼ï¼‰\n",
    "   use_rslora = False,   # æ˜¯å¦å¯ç”¨RSLoRAï¼ˆç§©ç¨³å®šLoRAï¼‰ï¼šFalseè¡¨ç¤ºä½¿ç”¨æ ‡å‡†LoRAï¼ˆQwen2.5-14Bæ— éœ€RSLoRAï¼‰\n",
    "   loftq_config = None,  # æ˜¯å¦å¯ç”¨LoftQï¼ˆé‡åŒ–æ„ŸçŸ¥LoRAåˆå§‹åŒ–ï¼‰ï¼šNoneè¡¨ç¤ºä¸å¯ç”¨ï¼ˆ4bité‡åŒ–å·²ä¼˜åŒ–ï¼Œæ— éœ€é¢å¤–åˆå§‹åŒ–ï¼‰\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75412f7fccd742ef9004b0a0a99fc109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We automatically added an EOS token to stop endless generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc166709dc84453a1b2f23e30681e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversations': [{'content': 'æ€€å­•37å‘¨æˆ‘æ†‹çš„ä¸Šå®å®èƒåŠ¨å¤šèƒå¿ƒå¼‚å¸¸æ€ä¹ˆå›äº‹', 'role': 'user'}, {'content': 'èƒåŠ¨é¢‘ç¹ï¼Œèƒå¿ƒå¿«ï¼Œè¦è€ƒè™‘èƒå„¿æ˜¯ä¸æ˜¯ç¼ºæ°§çš„è¡¨ç°ã€‚å»ºè®®å»åŒ»é™¢åšèƒå¿ƒç›‘æŠ¤ï¼Œå¦‚æœè¯„åˆ†ä½äº9åˆ†ï¼Œè¦å¸æ°§ç­‰å¤„ç†ã€‚', 'role': 'assistant'}], 'text': 'ä¸‹é¢æ˜¯ä¸€äº›æè¿°ä¸€äº›ä»»åŠ¡çš„è¯´æ˜ã€‚ç¼–å†™é€‚å½“å®Œæˆæ¯ä¸ªè¯·æ±‚çš„å“åº”ã€‚\\n\\n### æŒ‡ä»¤:\\næ€€å­•37å‘¨æˆ‘æ†‹çš„ä¸Šå®å®èƒåŠ¨å¤šèƒå¿ƒå¼‚å¸¸æ€ä¹ˆå›äº‹\\n\\n### å›åº”:\\nèƒåŠ¨é¢‘ç¹ï¼Œèƒå¿ƒå¿«ï¼Œè¦è€ƒè™‘èƒå„¿æ˜¯ä¸æ˜¯ç¼ºæ°§çš„è¡¨ç°ã€‚å»ºè®®å»åŒ»é™¢åšèƒå¿ƒç›‘æŠ¤ï¼Œå¦‚æœè¯„åˆ†ä½äº9åˆ†ï¼Œè¦å¸æ°§ç­‰å¤„ç†ã€‚<|im_end|>'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('json', data_files='med-train-dateset.json', split='train')\n",
    "chat_template = \"\"\"ä¸‹é¢æ˜¯ä¸€äº›æè¿°ä¸€äº›ä»»åŠ¡çš„è¯´æ˜ã€‚ç¼–å†™é€‚å½“å®Œæˆæ¯ä¸ªè¯·æ±‚çš„å“åº”ã€‚\n",
    "\n",
    "### æŒ‡ä»¤:\n",
    "{INPUT}\n",
    "\n",
    "### å›åº”:\n",
    "{OUTPUT}\"\"\"\n",
    "\n",
    "from unsloth import apply_chat_template\n",
    "\n",
    "dataset = apply_chat_template(\n",
    "    dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    chat_template=chat_template,\n",
    "   \n",
    ")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0540d0c134c14e6499fdd9fdbd796658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=12):   0%|          | 0/119397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[accelerate.utils.other|WARNING]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥TRLåº“çš„SFTTrainerç±»ï¼šä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç›‘ç£å¾®è°ƒè®¾è®¡çš„è®­ç»ƒå™¨\n",
    "# å°è£…äº†SFTçš„æ ¸å¿ƒé€»è¾‘ï¼ˆå¦‚åºåˆ—é•¿åº¦å¤„ç†ã€æ•°æ®é›†æ‰“åŒ…ã€LoRAé€‚é…ï¼‰ï¼Œæ¯”åŸç”ŸTraineræ›´é€‚é…LLMå¾®è°ƒ\n",
    "from trl import SFTTrainer\n",
    "# å¯¼å…¥Transformersçš„TrainingArgumentsç±»ï¼šç”¨äºå®šä¹‰æ‰€æœ‰è®­ç»ƒç›¸å…³çš„è¶…å‚æ•°ï¼ˆæ‰¹æ¬¡ã€å­¦ä¹ ç‡ã€æ­¥æ•°ç­‰ï¼‰\n",
    "from transformers import TrainingArguments\n",
    "# å¯¼å…¥Unslothçš„ç¡¬ä»¶æ£€æµ‹å·¥å…·å‡½æ•°ï¼šæ£€æµ‹å½“å‰GPUæ˜¯å¦æ”¯æŒbfloat16ç²¾åº¦ï¼Œç”¨äºè‡ªåŠ¨é€‰æ‹©æ··åˆç²¾åº¦ç­–ç•¥\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# åˆå§‹åŒ–SFTè®­ç»ƒå™¨ï¼Œæ•´åˆæ¨¡å‹ã€åˆ†è¯å™¨ã€æ•°æ®é›†å’Œè®­ç»ƒå‚æ•°\n",
    "trainer = SFTTrainer(\n",
    "    model = model,  # ä¼ å…¥å·²é…ç½®LoRAçš„Qwen2.5-14Bé‡åŒ–æ¨¡å‹å®ä¾‹\n",
    "    tokenizer = tokenizer,  # ä¼ å…¥æ¨¡å‹é…å¥—çš„åˆ†è¯å™¨å®ä¾‹ï¼Œç”¨äºæ–‡æœ¬tokenåŒ–\n",
    "    train_dataset = dataset,  # ä¼ å…¥é¢„å¤„ç†åçš„è®­ç»ƒæ•°æ®é›†ï¼ˆéœ€åŒ…å«\"text\"å­—æ®µï¼Œå­˜å‚¨å¾…å¾®è°ƒçš„æŒ‡ä»¤/æ–‡æœ¬ï¼‰\n",
    "    dataset_text_field = \"text\",  # æŒ‡å®šæ•°æ®é›†ä¸­å­˜å‚¨è®­ç»ƒæ–‡æœ¬çš„å­—æ®µåï¼ˆéœ€ä¸æ•°æ®é›†ç»“æ„åŒ¹é…ï¼‰\n",
    "    max_seq_length = 2048,  # è®¾å®šæ¨¡å‹è¾“å…¥çš„æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆQwen2.5-14Bæ”¯æŒ4096ï¼Œ2048å¹³è¡¡æ˜¾å­˜ä¸æ•ˆæœï¼‰\n",
    "    dataset_num_proc = 2,  # æ•°æ®é›†é¢„å¤„ç†çš„å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆ2é€‚é…æ¶ˆè´¹çº§CPUï¼ŒåŠ é€Ÿæ•°æ®é›†åŠ è½½/åˆ†è¯ï¼‰\n",
    "    packing = False,  # æ˜¯å¦å¯ç”¨æ•°æ®é›†æ‰“åŒ…ï¼šFalseè¡¨ç¤ºä¸æ‰“åŒ…ï¼ˆæŒ‡ä»¤å¾®è°ƒåœºæ™¯æ¨èFalseï¼Œé¿å…ä¸Šä¸‹æ–‡æ··ä¹±ï¼‰\n",
    "                      # æ‰“åŒ…ä¼šå°†çŸ­æ–‡æœ¬æ‹¼æ¥æˆå›ºå®šé•¿åº¦ï¼Œé€‚åˆå¤§æ–‡æœ¬è¯­æ–™ï¼ŒæŒ‡ä»¤å¾®è°ƒæ— éœ€æ­¤æ“ä½œ\n",
    "    # å®šä¹‰æ ¸å¿ƒè®­ç»ƒè¶…å‚æ•°ï¼Œé€šè¿‡TrainingArgumentså®ä¾‹ä¼ å…¥\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,  # å•GPUçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼ˆ2é€‚é…10GB+æ˜¾å­˜ï¼Œå¯æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰\n",
    "        gradient_accumulation_steps = 4,  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼šå°†4ä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦ç´¯ç§¯åå†æ›´æ–°å‚æ•°\n",
    "                                          # ç­‰æ•ˆäºæ€»æ‰¹æ¬¡å¤§å°=2*4=8ï¼Œæ—¢ä¿è¯æ‰¹æ¬¡å¤§å°åˆé™ä½å•æ­¥æ˜¾å­˜å ç”¨\n",
    "        warmup_steps = 5,  # å­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°ï¼šå‰5æ­¥å­¦ä¹ ç‡ä»0çº¿æ€§å‡è‡³è®¾å®šå€¼ï¼Œé¿å…åˆå§‹å­¦ä¹ ç‡è¿‡å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š\n",
    "        max_steps = 60,  # æœ€å¤§è®­ç»ƒæ­¥æ•°ï¼ˆæ›¿ä»£epochsï¼Œæ›´æ˜“æ§åˆ¶å¾®è°ƒæ—¶é•¿ï¼‰ï¼š60æ­¥é€‚åˆå°æ•°æ®é›†ï¼ˆå¦‚åƒçº§æ ·æœ¬ï¼‰\n",
    "        learning_rate = 2e-4,  # LoRAå¾®è°ƒçš„å­¦ä¹ ç‡ï¼ˆ2e-4æ˜¯Qwen2.5-14B+LoRAçš„ç»å…¸æ¨èå€¼ï¼‰\n",
    "        fp16 = not is_bfloat16_supported(),  # æ˜¯å¦å¯ç”¨FP16æ··åˆç²¾åº¦ï¼šç¡¬ä»¶ä¸æ”¯æŒBF16æ—¶è‡ªåŠ¨å¯ç”¨FP16\n",
    "        bf16 = is_bfloat16_supported(),  # æ˜¯å¦å¯ç”¨BF16æ··åˆç²¾åº¦ï¼šA100/RTX 3090/4090ç­‰æ–°GPUæ”¯æŒï¼Œç²¾åº¦æ›´é«˜ã€é€Ÿåº¦æ›´å¿«\n",
    "        logging_steps = 1,  # æ—¥å¿—æ‰“å°æ­¥æ•°ï¼šæ¯è®­ç»ƒ1æ­¥æ‰“å°ä¸€æ¬¡æŸå¤±ã€å­¦ä¹ ç‡ç­‰ä¿¡æ¯ï¼Œä¾¿äºç›‘æ§è®­ç»ƒçŠ¶æ€\n",
    "        optim = \"adamw_8bit\",  # å¯ç”¨8ä½é‡åŒ–çš„AdamWä¼˜åŒ–å™¨ï¼šç›¸æ¯”åŸç”ŸAdamWæ˜¾å­˜å ç”¨é™ä½50%ï¼Œä¸æŸå¤±è®­ç»ƒæ•ˆæœ\n",
    "        weight_decay = 0.01,  # æƒé‡è¡°å‡ç³»æ•°ï¼š0.01ç”¨äºæŠ‘åˆ¶è¿‡æ‹Ÿåˆï¼Œå¹³è¡¡æ¨¡å‹æ³›åŒ–èƒ½åŠ›\n",
    "        lr_scheduler_type = \"linear\",  # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šçº¿æ€§è¡°å‡ï¼ˆé¢„çƒ­åå­¦ä¹ ç‡çº¿æ€§é™è‡³0ï¼‰ï¼Œé€‚é…LoRAå¾®è°ƒ\n",
    "        seed = 3407,  # éšæœºç§å­ï¼šå›ºå®šç§å­ä¿è¯è®­ç»ƒè¿‡ç¨‹å¯å¤ç°ï¼ˆLLMå¾®è°ƒé€šç”¨å€¼ï¼‰\n",
    "        output_dir = \"outputs\",  # è®­ç»ƒç»“æœä¿å­˜è·¯å¾„ï¼šå­˜å‚¨æ¨¡å‹æƒé‡ã€æ—¥å¿—ã€æ£€æŸ¥ç‚¹ç­‰\n",
    "        report_to = \"none\",  # ç¦ç”¨ç¬¬ä¸‰æ–¹æ—¥å¿—å·¥å…·ï¼ˆå¦‚WandBï¼‰ï¼šä»…æœ¬åœ°æ‰“å°æ—¥å¿—ï¼Œç®€åŒ–è®­ç»ƒæµç¨‹\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 119,397 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 68,812,800 of 14,838,846,464 (0.46% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.859300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.610900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.298500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.302500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.241300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.960200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.985400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.252800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.911700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.366700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.844800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.913000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¯èƒ½æ˜¯è‚ ç—‰æŒ›å¼•èµ·çš„ï¼Œå»ºè®®æœç”¨å±±è¨èªç¢±ç‰‡æ²»ç–—<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "# å°†æ¨¡å‹åˆ‡æ¢ä¸ºæ¨ç†æ¨¡å¼ï¼ˆUnslothå°è£…çš„ä¼˜åŒ–æ–¹æ³•ï¼‰\n",
    "# è‡ªåŠ¨ç¦ç”¨è®­ç»ƒç›¸å…³çš„æ¢¯åº¦è®¡ç®—ã€dropoutç­‰ï¼Œå¯ç”¨æ¨ç†ä¼˜åŒ–ï¼ˆå¦‚KVç¼“å­˜ï¼‰ï¼Œæå‡ç”Ÿæˆé€Ÿåº¦ã€é™ä½æ˜¾å­˜å ç”¨\n",
    "FastLanguageModel.for_inference(model) \n",
    "\n",
    "# å®šä¹‰å¯¹è¯å†å²/ç”¨æˆ·è¾“å…¥ï¼Œéµå¾ªQwen2.5çš„å¯¹è¯æ ¼å¼ï¼ˆrole: user/assistantï¼‰\n",
    "# åˆ—è¡¨ä¸­æ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€è½®å¯¹è¯ï¼Œæ­¤å¤„ä»…åŒ…å«ç”¨æˆ·çš„æé—®ï¼šâ€œæˆ‘è‚šå­ç–¼â€\n",
    "messages = [                   \n",
    "    {\"role\": \"user\", \"content\": \"æˆ‘è‚šå­ç–¼\"},\n",
    "]\n",
    "\n",
    "# ä½¿ç”¨åˆ†è¯å™¨çš„å¯¹è¯æ¨¡æ¿å¤„ç†è¾“å…¥ï¼Œè½¬æ¢ä¸ºæ¨¡å‹å¯è¯†åˆ«çš„token IDï¼ˆå¼ é‡æ ¼å¼ï¼‰\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,  # ä¼ å…¥å¯¹è¯åˆ—è¡¨\n",
    "    add_generation_prompt = True,  # è‡ªåŠ¨æ·»åŠ â€œåŠ©æ‰‹å›å¤å‰ç¼€â€ï¼ˆQwen2.5è¦æ±‚çš„æ ¼å¼ï¼‰ï¼Œå‘Šè¯‰æ¨¡å‹æ¥ä¸‹æ¥è¦ç”ŸæˆåŠ©æ‰‹å›å¤\n",
    "    return_tensors = \"pt\",  # è¿”å›PyTorchå¼ é‡ï¼ˆptï¼‰ï¼Œé€‚é…æ¨¡å‹çš„å¼ é‡è®¡ç®—\n",
    ").to(\"cuda\")  # å°†è¾“å…¥å¼ é‡ç§»è‡³GPUï¼ˆcudaï¼‰ï¼Œä¸æ¨¡å‹çš„è¿è¡Œè®¾å¤‡ä¸€è‡´\n",
    "\n",
    "# å¯¼å…¥Transformersçš„TextStreamerç±»ï¼šå®ç°æµå¼è¾“å‡ºï¼ˆé€å­—/é€å¥è¿”å›å›å¤ï¼Œè€Œéä¸€æ¬¡æ€§è¾“å‡ºï¼‰\n",
    "from transformers import TextStreamer\n",
    "# åˆå§‹åŒ–æµå¼è¾“å‡ºå™¨ï¼Œç»‘å®šåˆ†è¯å™¨ï¼›skip_prompt=Trueè¡¨ç¤ºè·³è¿‡è¾“å…¥æç¤ºè¯ï¼ˆä»…è¾“å‡ºæ¨¡å‹ç”Ÿæˆçš„å›å¤ï¼‰\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹çš„generateæ–¹æ³•ç”Ÿæˆå›å¤ï¼Œæµå¼è¾“å‡ºç»“æœ\n",
    "# _ = å¿½ç•¥è¿”å›å€¼ï¼ˆå› streamerå·²å®æ—¶æ‰“å°å›å¤ï¼Œæ— éœ€é¢å¤–å­˜å‚¨ç”Ÿæˆçš„token IDï¼‰\n",
    "_ = model.generate(\n",
    "    input_ids,  # ä¼ å…¥å¤„ç†åçš„è¾“å…¥å¼ é‡\n",
    "    streamer = text_streamer,  # ç»‘å®šæµå¼è¾“å‡ºå™¨ï¼Œå®æ—¶æ‰“å°å›å¤\n",
    "    max_new_tokens = 128,  # é™åˆ¶ç”Ÿæˆçš„æœ€å¤§æ–°tokenæ•°ï¼ˆ128è¶³å¤Ÿè¦†ç›–æ—¥å¸¸å¯¹è¯å›å¤é•¿åº¦ï¼‰\n",
    "    pad_token_id = tokenizer.eos_token_id,  # æŒ‡å®špadding tokenä¸ºEOSï¼ˆç»“æŸç¬¦ï¼‰ï¼Œé¿å…ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°paddingé”™è¯¯\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging LoRA weights into 4bit model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging finished.\n",
      "Unsloth: Found skipped modules: ['lm_head']. Updating config.\n",
      "Unsloth: Saving merged 4bit model to qwen25-14b-offical-finetuned-bnb-4bit...\n",
      "Unsloth: Merged 4bit model saved.\n",
      "Unsloth: Merged 4bit model process completed.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"qwen25-14b-offical-finetuned-bnb-4bit\", tokenizer, save_method=\"merged_4bit_forced\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
